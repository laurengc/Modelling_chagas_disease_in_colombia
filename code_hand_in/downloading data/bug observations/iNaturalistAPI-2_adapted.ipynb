{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArUWoQITW_7",
        "outputId": "72158e88-7507-4030-846b-22f23e6d2668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyinaturalist in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (0.16.0)\n",
            "Requirement already satisfied: requests-cache>=0.7.4 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (0.9.3)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (2.8.2)\n",
            "Requirement already satisfied: requests-ratelimiter>=0.2.1 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (0.3.1)\n",
            "Requirement already satisfied: rich<10.12,>=10.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (10.11.0)\n",
            "Requirement already satisfied: appdirs>=1.4 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (1.4.4)\n",
            "Requirement already satisfied: python-forge>=18.6 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (18.6.0)\n",
            "Requirement already satisfied: keyring>=22.3 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (23.5.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from pyinaturalist) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from keyring>=22.3->pyinaturalist) (4.11.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from python-dateutil>=2.0->pyinaturalist) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests>=2.20->pyinaturalist) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests>=2.20->pyinaturalist) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests>=2.20->pyinaturalist) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests>=2.20->pyinaturalist) (3.3)\n",
            "Requirement already satisfied: cattrs<2.0,>=1.8 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests-cache>=0.7.4->pyinaturalist) (1.10.0)\n",
            "Requirement already satisfied: url-normalize<2.0,>=1.4 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests-cache>=0.7.4->pyinaturalist) (1.4.3)\n",
            "Requirement already satisfied: pyrate-limiter>=2.6.3 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from requests-ratelimiter>=0.2.1->pyinaturalist) (2.8.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from rich<10.12,>=10.0->pyinaturalist) (0.4.4)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from rich<10.12,>=10.0->pyinaturalist) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from rich<10.12,>=10.0->pyinaturalist) (2.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/laurengomezcullen/opt/anaconda3/envs/python_Env/lib/python3.8/site-packages (from importlib-metadata>=3.6->keyring>=22.3->pyinaturalist) (3.8.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyinaturalist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y8y9r8sITbLn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyinaturalist import *\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uYBmynwZTp3s"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The observations function only extracts data from first page in order to avoid exceeding the rate limit included in the API Recommended Practices, so need to loop through to access all observations\n",
        "if working with Mexico then: place_id = 6793\n",
        "if working with Colombia then: place_id = 7196\n",
        "'''\n",
        "def download_data(place_id):\n",
        "    #finding the number of times that i need to loop through\n",
        "    observations_dict = get_observations(place_id= place_id, subview= 'map', taxon_id=472290, per_page = 50, quality_grade=\"research\")\n",
        "    number_of_observations = observations_dict['total_results'] #int object\n",
        "    iterations = math.ceil(number_of_observations/50)\n",
        "    observations = observations_dict['results']\n",
        "\n",
        "    #creating one list of observations\n",
        "    for i in range(2,iterations+1):\n",
        "        observation_dict = get_observations(place_id= place_id, subview= 'map', taxon_id=472290, page = i, per_page = 50, quality_grade=\"research\")\n",
        "        observation = observation_dict['results']\n",
        "        observations += observation\n",
        "    print(\"observation #: \" + str(number_of_observations))\n",
        "\n",
        "    return observations, number_of_observations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qZ1Htza0Rse",
        "outputId": "43cefc51-2f1b-445c-d1fa-e1e61cc2de02"
      },
      "outputs": [],
      "source": [
        "#at this point we have a list of dictionaries, each dictionary carrying information about an observation. this function gets a list of the important information from one dictionary\n",
        "def get_data(data):\n",
        "    columns = ['id', 'species_guess', 'positional_accuracy', 'location']\n",
        "    items = list(map(data.get, columns))\n",
        "    items += items.pop() #pop removes and returns the last element of the list, which is needed as the location is a list of the longitude and latitude, and so to break this up into two separate entries we can just removed location and use + to add it back in a divided way\n",
        "    return items\n",
        "\n",
        "\n",
        "#reshaping the array so that it is like a dataframe\n",
        "def reshaped_array(observations_reduced, number_of_observations, columns, place_id):\n",
        "  obs_decomposed = np.hstack([*observations_reduced])\n",
        "  if len(columns) == len(observations_reduced[0]):\n",
        "    observations_array = obs_decomposed.reshape(number_of_observations, len(columns))\n",
        "  elif len(columns) == len(observations_reduced[0]) -1: \n",
        "    if place_id == 'any':\n",
        "        observations_array = obs_decomposed.reshape(len(observations_reduced), len(columns)+1)\n",
        "    else:\n",
        "        observations_array = obs_decomposed.reshape(number_of_observations, len(columns)+1)\n",
        "    columns_final = columns\n",
        "    columns_final.remove('location')\n",
        "    columns_final.append('latitude')\n",
        "    columns_final.append('longitude')\n",
        "  else:\n",
        "    print('error - check the format of the data in the columns you have chosen')\n",
        "    exit()\n",
        "  return columns_final, observations_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_DymoVGojnTd"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    countries = [\"Mexico\", \"Colombia\", \"Texas\"]\n",
        "    place_ids = [6793, 7196 ,18]\n",
        "    # countries = [\"Mexico_and_texas_border\"]\n",
        "    # place_ids = [\"any\"]\n",
        "    for i in place_ids:\n",
        "        print(i)\n",
        "        observations, number_of_observations = download_data(i)\n",
        "        print(\"observations vector length: \" + str(len(observations)))\n",
        "\n",
        "        #select the columns of interest, unhashtag the first line to see the options\n",
        "        #print(np.array(list(observations[0].keys())))\n",
        "        columns = ['id', 'species_guess', 'positional_accuracy', 'location']\n",
        "\n",
        "        #vectorise the get_data function\n",
        "        #print(observations[0]['positional_accuracy'])\n",
        "        v_get_data = np.vectorize(get_data, otypes=[list])\n",
        "\n",
        "\n",
        "        #get the reduced data\n",
        "        observations_reduced = v_get_data(observations)\n",
        "        print(\"observations_reduced_length: \" + str(len(observations_reduced)))\n",
        "\n",
        "        #reshape the array\n",
        "        columns_final, observations_array = reshaped_array(observations_reduced, number_of_observations, columns, i)\n",
        "\n",
        "        #creating the dataframe\n",
        "        observations_df = pd.DataFrame(observations_array, columns = columns_final)\n",
        "\n",
        "        #adapt to match the gbif data\n",
        "        observations_df['subFamily'] = 'Triatominae'\n",
        "        new_columns = {'positional_accuracy' : 'coordinateUncertaintyInMeters', 'species_guess': 'scientificName'}\n",
        "        observations_matching = observations_df.rename(columns = new_columns)\n",
        "\n",
        "        #write to a df\n",
        "        observations_matching.to_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_' + countries[place_ids.index(i)] + '_matching_gbif.csv', index = False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "bmHf0hJkv4M8",
        "outputId": "019b9d83-84ff-4da2-f560-1ab15b314073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6793\n",
            "observation #: 387\n",
            "observations vector length: 387\n",
            "observations_reduced_length: 387\n",
            "7196\n",
            "observation #: 31\n",
            "observations vector length: 31\n",
            "observations_reduced_length: 31\n",
            "18\n",
            "observation #: 657\n",
            "observations vector length: 657\n",
            "observations_reduced_length: 657\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1044\n"
          ]
        }
      ],
      "source": [
        "#concatenate the texas and mexico ones\n",
        "df_mexico = pd.read_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_Mexico_matching_gbif.csv')\n",
        "df_texas = pd.read_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_Texas_matching_gbif.csv')\n",
        "\n",
        "df_texas_and_mexico = pd.concat([df_mexico, df_texas])\n",
        "df_texas_and_mexico.to_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_Mexico_and_texas_matching_gbif.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #add on for the texas and border data which I cut in QGIS from the mexico and texas data above. This can be done using the PYQGIS packages here\n",
        "\n",
        "# observations_df = pd.read_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_mexico_border_and_texas.csv')\n",
        "# #adapt to match the gbif data\n",
        "# observations_df['subFamily'] = 'Triatominae'\n",
        "# new_columns = {'positional_accuracy' : 'coordinateUncertaintyInMeters', 'species_guess': 'scientificName'}\n",
        "# observations_matching = observations_df.rename(columns = new_columns)\n",
        "\n",
        "# #write to a df\n",
        "# observations_matching.to_csv('/Users/laurengomezcullen/Documents/Cambridge/Fourth/Project/final/data/possible_kissing_bug_data/inaturalist/inaturalist_observations_mexico_border_and_texas_matching_gbif.csv', index = False )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "iNaturalistAPI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
